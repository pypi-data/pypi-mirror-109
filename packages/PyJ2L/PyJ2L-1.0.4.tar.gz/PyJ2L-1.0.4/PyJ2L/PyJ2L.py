import cv2
import numpy as np
import time
import autopy
import mediapipe as mp
import math
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume
import cvzone
import face_recognition as fr
import os
from datetime import datetime
from tkinter import *#Installations
import tkinter.messagebox
from tkcalendar import*
import tkinter as tk
from tkinter.ttk import Progressbar
from time import sleep
import webbrowser
import tkinter.ttk as ttk
import tkinter.messagebox as tkMessageBox
import sqlite3
import parser
import tkcalendar

def Print(val):
    print(val)


class Make():
    def Life_Calculator():
        root = Tk()
        space = " "
        root.title(185 * space + "                  Life Calculator                      ")
        #######700
        root.geometry("1285x630+56+0")

        #FRAMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMEEEEEEEEEEESSSSSSSSSSSSSSSSSSS
        MFrame = Frame(root, bd=10, width = 1245, height=680, relief=RIDGE, bg="cyan")
        MFrame.grid()

        TFrame = Frame(MFrame, bd=7, width = 1245, height=100, relief=RIDGE,)
        TFrame.grid(row=0,column=0)

        Top3Frame = Frame(MFrame, bd=5, width = 1245, height=500, relief=RIDGE,)
        Top3Frame.grid(row=1,column=0)

        LFrame = Frame(Top3Frame, bd=5, width = 1245, height=400,padx=2, relief=RIDGE, bg="cyan")
        LFrame.pack(side=LEFT)
        LFrame1 = Frame(LFrame, bd=5, width = 600, height=180,padx=2,pady=4 ,relief=RIDGE,)
        LFrame1.pack(side=TOP, padx=10,pady=12)

        RFrame = Frame(Top3Frame, bd=5, width = 320, height=400,padx=2, relief=RIDGE, bg="cyan")
        RFrame.pack(side=RIGHT,padx=2)
        RFrame1 = Frame(RFrame, bd=5, width = 310, height=300,padx=2,pady=2 ,relief=RIDGE,)
        RFrame1.pack(side=TOP, padx=5,pady=6)

        lblTitle = Label(TFrame, font=('arial',50,'bold'), text="Life Calculator", bd=7)
        lblTitle.grid(row=0,column=0,padx=88)
        #=================================================================================
        DOB= StringVar()
        CDate= StringVar()
        Days= StringVar()
        Ages= StringVar()
        Months= StringVar()
        Weeks= StringVar()
        Hours= StringVar()
        Minutes= StringVar()
        Seconds= StringVar()

        #=================================================================================
        def Reset():
            DOB.set("")
            CDate.set("")
            Days.set("")
            Ages.set("")
            Months.set("")
            Weeks.set("")
            Hours.set("")
            Minutes.set("")
            Seconds.set("")
            entFirstName.delete(0,END)
            entSurName.delete(0,END)

        def iExit():
            iExit = tkinter.messagebox.askyesno("Life Calculator", "Confirm if you want to exit")
            if iExit>0:
                root.destroy()
                return

        def Cal():
            CurrentDate = (DentCD.get_date())
            DOBDate = (DentDOB.get_date())
            Day = (abs ((CurrentDate - DOBDate).days))
            Days.set(str(Day))
            DOB.set("")
            Age = int(Days.get())
            Agess = (Age/365)
            Ages.set(str('%.0f'%Agess))
            Weeks.set(str('%.0f'%(Age/7)))
            Month = int(Weeks.get())
            Months.set(str('%.0f'%(Month/4)))
            Hours.set(str('%.0f'%(Age*24)))
            Minute = int(Hours.get())
            Minutes.set(str('%.0f'%Minute *60))
            Second = int(Minutes.get())
            Seconds.set(str('%.0f'%Second *60))
        ##    CDate.set("")
        ##    Days.set("")
        ##    Ages.set("")
        ##    Months.set("")
        ##    Weeks.set("")
        ##    Hours.set("")
        ##    Minutes.set("")
        ##    Seconds.set("")
        ##    entFirstName.delete(0,END)
        ##    entSurName.delete(0,END)
        #====================================================================================
        cal=Calendar(RFrame1,selectmode="day",year=2021,month=5,day=17, date_pattern='dd/mm/y',
                        font=('arial',16,'bold'))
        cal.grid(row=0,column=0,padx=10)
        #=========================================================================
        lblFirstName = Label(LFrame1, font=('arial',16,'bold'), text="FirstName", bd=7,anchor='w',justify = LEFT)
        lblFirstName.grid(row=0,column=0,sticky = W,padx=5)
        entFirstName = Entry(LFrame1, font=('arial',16,'bold'), bd=5,width=48,justify = LEFT)
        entFirstName.grid(row=0,column=1)

        lblSurName = Label(LFrame1, font=('arial',16,'bold'), text="SurName", bd=7,anchor='w',justify = LEFT)
        lblSurName.grid(row=1,column=0,sticky = W,padx=5)
        entSurName = Entry(LFrame1, font=('arial',16,'bold'), bd=5,width=48,justify = LEFT)
        entSurName.grid(row=1,column=1)

        lblDOB = Label(LFrame1, font=('arial',16,'bold'), text="Date of Birth", bd=7,anchor='w',justify = LEFT)
        lblDOB.grid(row=2,column=0,sticky = W,padx=5)
        DentDOB = DateEntry(LFrame1, font=('arial',16,'bold'), bd=5,width=46,borderwidth= 2,date_pattern='dd/mm/yyyy')
        DentDOB.grid(row=2,column=1)

        lblCD = Label(LFrame1, font=('arial',16,'bold'), text="Current Date", bd=7,anchor='w',justify = LEFT)
        lblCD.grid(row=3,column=0,sticky = W,padx=5)
        DentCD = DateEntry(LFrame1, font=('arial',16,'bold'), bd=5,width=46,borderwidth= 2,date_pattern='dd/mm/yyyy')
        DentCD.grid(row=3,column=1)

        lblDays = Label(LFrame1, font=('arial',16,'bold'), text="Days", bd=7,anchor='w',justify = LEFT)
        lblDays.grid(row=4,column=0,sticky = W,padx=5)
        entDays = Entry(LFrame1, font=('arial',16,'bold'), bd=5,width=48,justify = LEFT,textvariable = Days)
        entDays.grid(row=4,column=1)

        lblAge = Label(LFrame1, font=('arial',16,'bold'), text="Age", bd=7,anchor='w',justify = LEFT)
        lblAge.grid(row=5,column=0,sticky = W,padx=5)
        entAge = Entry(LFrame1, font=('arial',16,'bold'), bd=5,width=48,justify = LEFT,textvariable=Ages)
        entAge.grid(row=5,column=1)

        lblMonths = Label(LFrame1, font=('arial',16,'bold'), text="Months", bd=7,anchor='w',justify = LEFT)
        lblMonths.grid(row=6,column=0,sticky = W,padx=5)
        entMonths = Entry(LFrame1, font=('arial',16,'bold'), bd=5,width=48,justify = LEFT,textvariable = Months)
        entMonths.grid(row=6,column=1)

        lblWeeks = Label(LFrame1, font=('arial',16,'bold'), text="Weeks", bd=7,anchor='w',justify = LEFT)
        lblWeeks.grid(row=7,column=0,sticky = W,padx=5)
        entWeeks = Entry(LFrame1, font=('arial',16,'bold'), bd=5,width=48,justify = LEFT,textvariable = Weeks)
        entWeeks.grid(row=7,column=1)

        lblHours = Label(LFrame1, font=('arial',16,'bold'), text="Hours", bd=7,anchor='w',justify = LEFT)
        lblHours.grid(row=8,column=0,sticky = W,padx=5)
        entHours = Entry(LFrame1, font=('arial',16,'bold'), bd=5,width=48,justify = LEFT,textvariable = Hours)
        entHours.grid(row=8,column=1)

        lblMinutes = Label(LFrame1, font=('arial',16,'bold'), text="Minutes", bd=7,anchor='w',justify = LEFT)
        lblMinutes.grid(row=9,column=0,sticky = W,padx=5)
        entMinutes= Entry(LFrame1, font=('arial',16,'bold'), bd=5,width=48,justify = LEFT,textvariable = Minutes)
        entMinutes.grid(row=9,column=1)

        lblSeconds = Label(LFrame1, font=('arial',16,'bold'), text="Seconds", bd=7,anchor='w',justify = LEFT)
        lblSeconds.grid(row=10,column=0,sticky = W,padx=5)
        entSeconds = Entry(LFrame1, font=('arial',16,'bold'), bd=5,width=48,justify = LEFT,textvariable = Seconds)
        entSeconds.grid(row=10,column=1)

        btnCalculate = Button(RFrame1, padx=18,bd=7,font=('Helvetica',18,'bold'), width = 23,text="Calculate",
                                bg='cyan',command = Cal)
        btnCalculate.grid(row=1,column=0,pady=2)

        btnReset = Button(RFrame1, padx=18,bd=7,font=('Helvetica',18,'bold'), width = 23,text="Reset",
                                bg='cyan',command = Reset)
        btnReset.grid(row=2,column=0,pady=2)

        btnExit = Button(RFrame1, padx=18,bd=7,font=('Helvetica',18,'bold'), width = 23,text="Exit",
                                bg='cyan',command = iExit)
        btnExit.grid(row=3,column=0,pady=2)




        root.mainloop()


class htm():
    class handDetector():
        def __init__(self, mode=False,maxHands=2,detectionCon=0.5,trackCon=0.5):
            self.mode = mode
            self.maxHands = maxHands
            self.detectionCon = detectionCon
            self.trackCon = trackCon
            
            self.mpHands = mp.solutions.hands
            self.hands = self.mpHands.Hands(self.mode,self.maxHands,
                                            self.detectionCon,self.trackCon)
            self.mpDraw = mp.solutions.drawing_utils

            self.tipIds = [4, 8, 12, 16, 20]
        def findHands(self, img,draw = True):
            
            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            self.results = self.hands.process(imgRGB)
            #print(results.multi_hand_landmarks)
            if self.results.multi_hand_landmarks:
                for handLms in self.results.multi_hand_landmarks:
                    if draw:
                        self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)
            return img           
                        
        def findPosition(self, img, handNo=0, draw = True):
            xList = []
            yList = []
            bbox = []
            self.lmList = []
            if self.results.multi_hand_landmarks:
                myHand = self.results.multi_hand_landmarks[handNo]
                for id , lm in enumerate(myHand.landmark):
                    # print(id, lm)
                    h, w, c = img.shape
                    cx, cy = int(lm.x*w), int(lm.y*h)
                    xList.append(cx)
                    yList.append(cy)
                    #print(id,cx, cy)
                    self.lmList.append([id, cx, cy])
                    if draw:
                        cv2.circle(img, (cx, cy), 5, (0,0,255),cv2.FILLED)
                xmin, xmax = min(xList), max(xList)
                ymin, ymax = min(yList), max(yList)
                bbox = xmin, ymin, xmax, ymax
                if draw:
                    cv2.rectangle(img, (bbox[0]-20,bbox[1]-20),
                            (bbox[2]+20,bbox[3]+20),(0,255,0),2)
                
            return self.lmList, bbox
        def findDistance(self,p1,p2,img,draw=True):
            x1,y1 = self.lmList[p1][1],self.lmList[p1][2]
            x2, y2 = self.lmList[p2][1], self.lmList[p2][2]
            cx, cy = (x1+x2) //2, (y1 +y2) //2

            if draw:
                cv2.circle(img,(x1,y1), 10, (0,255,0), cv2.FILLED)
                cv2.circle(img,(x2,y2), 10, (0,255,0), cv2.FILLED)
                cv2.line(img, (x1,y1), (x2,y2), (255,0,255),3)
                cv2.circle(img,(cx,cy), 10, (255,0,255), cv2.FILLED)

            length = math.hypot(x2 - x1, y2 - y1)
            return length,img,[x1,y1,x2,y2,cx,cy]
            
        def FINGUP(self):
            fingers = []

            if self.lmList[self.tipIds[0]][1] < self.lmList[self.tipIds[0] - 1][1]:
                fingers.append(1)
            else:
                fingers.append(0)
                
            for id in range(1, 5):
                if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:
                    fingers.append(1)
                else:
                    fingers.append(0)
            return fingers
        def fingersUp(self):
            if self.results.multi_hand_landmarks:
                myHandType = self.handType()
                fingers = []
                # Thumb
                if myHandType == "Right":
                    if self.lmList[self.tipIds[0]][1] > self.lmList[self.tipIds[0] - 1][1]:
                        fingers.append(1)
                    else:
                        fingers.append(0)
                else:
                    if self.lmList[self.tipIds[0]][1] < self.lmList[self.tipIds[0] - 1][1]:
                        fingers.append(1)
                    else:
                        fingers.append(0)

                # 4 Fingers
                for id in range(1, 5):
                    if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:
                        fingers.append(1)
                    else:
                        fingers.append(0)
            return fingers
        def handType(self):
            if self.results.multi_hand_landmarks:
                if self.lmList[17][1] < self.lmList[5][1]:
                    return "Right"
                else:
                    return "Left"

            

    def main():
        pTime = 0
        cTime = 0
        cap = cv2.VideoCapture(0)
        detector = htm.handDetector()
        while True:
            success, img = cap.read()
            img = detector.findHands(img)
            lmList, bbox = detector.findPosition(img)
            #if len(lmList) !=0 :
                #print(lmList[4])
                
            cTime = time.time()
            fps = 1/(cTime-pTime)
            pTime = cTime

            cv2.putText(img, str(int(fps)),(10,70), cv2.FONT_HERSHEY_PLAIN,3,
                        (255,0,255), 3)
                    
            cv2.imshow("WebCam", img)
            cv2.waitKey(1)

        if __name__ == "__main__":
            main()
        
class htm1():
    class handDetector1():
        def __init__(self, mode=False,maxHands=2,detectionCon=0.5,trackCon=0.5):
            self.mode = mode
            self.maxHands = maxHands
            self.detectionCon = detectionCon
            self.trackCon = trackCon
            
            self.mpHands = mp.solutions.hands
            self.hands = self.mpHands.Hands(self.mode,self.maxHands,
                                            self.detectionCon,self.trackCon)
            self.mpDraw = mp.solutions.drawing_utils

            self.tipIds = [4, 8, 12, 16, 20]
        def findHands(self, img,draw = True):
            
            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            self.results = self.hands.process(imgRGB)
            #print(results.multi_hand_landmarks)
            if self.results.multi_hand_landmarks:
                for handLms in self.results.multi_hand_landmarks:
                    if draw:
                        self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)
            return img           
                        
        def findPosition(self, img, handNo=0, draw = True):
            self.lmList = []
            if self.results.multi_hand_landmarks:
                myHand = self.results.multi_hand_landmarks[handNo]
                for id , lm in enumerate(myHand.landmark):
                # print(id, lm)
                    h, w, c = img.shape
                    cx, cy = int(lm.x*w), int(lm.y*h)
                    #print(id,cx, cy)
                    self.lmList.append([id, cx, cy])
                    if draw:
                        cv2.circle(img, (cx, cy), 15, (255,0,255),cv2.FILLED)
            return self.lmList
        def FINGUP(self):
            fingers = []

            if self.lmList[self.tipIds[0]][1] < self.lmList[self.tipIds[0] - 1][1]:
                fingers.append(1)
            else:
                fingers.append(0)
                
            for id in range(1, 5):
                if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:
                    fingers.append(1)
                else:
                    fingers.append(0)
            return fingers
        def fingersUp(self):
            if self.results.multi_hand_landmarks:
                myHandType = self.handType()
                fingers = []
                # Thumb
                if myHandType == "Right":
                    if self.lmList[self.tipIds[0]][1] > self.lmList[self.tipIds[0] - 1][1]:
                        fingers.append(1)
                    else:
                        fingers.append(0)
                else:
                    if self.lmList[self.tipIds[0]][1] < self.lmList[self.tipIds[0] - 1][1]:
                        fingers.append(1)
                    else:
                        fingers.append(0)

                # 4 Fingers
                for id in range(1, 5):
                    if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:
                        fingers.append(1)
                    else:
                        fingers.append(0)
            return fingers
        def handType(self):
            """
            Checks if the hand is left or right
            :return: "Right" or "Left"
            """
            if self.results.multi_hand_landmarks:
                if self.lmList[17][1] < self.lmList[5][1]:
                    return "Right"
                else:
                    return "Left"

            

    def main():
        pTime = 0
        cTime = 0
        cap = cv2.VideoCapture(0)
        detector = handDetector()
        while True:
            success, img = cap.read()
            img = detector.findHands(img)
            lmList = detector.findPosition(img)
            #if len(lmList) !=0 :
                #print(lmList[4])
                
            cTime = time.time()
            fps = 1/(cTime-pTime)
            pTime = cTime

            cv2.putText(img, str(int(fps)),(10,70), cv2.FONT_HERSHEY_PLAIN,3,
                        (255,0,255), 3)
                    
            cv2.imshow("WebCam", img)
            cv2.waitKey(1)

    if __name__ == "__main__":
        main()

class HandProjects():
    def Mouse(smoothening=20):

        wCam, hCam = 640,480

        frameR = 100 #CV2.REC

        smoothening = 7

        ####ScreenSize = 1536.0,864.0
        pTime = 0

        plocX,plocY = 0,0
        clocX, clocY = 0, 0

        cap = cv2.VideoCapture(0)
        cap.set(3, wCam)
        cap.set(4, hCam)


        detector = htm.handDetector(maxHands = 1,detectionCon = 0.85)
        wScr, hScr = autopy.screen.size()
        #print(wScr,hScr)
        while True:
            success, img = cap.read()
            img = detector.findHands(img)
            lmList, bbox = detector.findPosition(img,draw = True)

            if len(lmList) != 0:
                x1, y1 = lmList[8][1:]
                x2, y2 = lmList[12][1:]

                #print(x1,y1,x2,y2)
                fingers = detector.fingersUp()

                cv2.rectangle(img,(frameR,frameR),(wCam-frameR, hCam-frameR),
                                (0,0,255), 2)
                    
                #print(fingers)
                if fingers[1]==1 and fingers[2]==0:
                    x3 = np.interp(x1, (frameR,wCam-frameR),(0,wScr))
                    y3 = np.interp(y1, (frameR,hCam-frameR),(0,hScr))
                    clocX = plocX + (x3-plocX) /smoothening
                    clocY = plocY + (y3-plocY) /smoothening
                    
                    autopy.mouse.move(wScr-clocX,clocY)
                    cv2.circle(img,(x1,y1),15,(0,255,0),cv2.FILLED)
                    plocX,plocY = clocX, clocY


                if fingers[1]==1 and fingers[2] == 1:
                    length, img, lineInfo, = detector.findDistance(8,12, img)

                    #print(length)
                    if length <30:
                        cv2.circle(img, (lineInfo[4],lineInfo[5]),
                                15, (0, 0,255), cv2.FILLED)
                        autopy.mouse.click()

                    
                    


                
            cTime = time.time()
            fps = 1/(cTime-pTime)
            pTime = cTime
            cv2.putText(img,str(int(fps)),(20,50),cv2.FONT_HERSHEY_PLAIN,3,
                        (255,0,0),3)
            cv2.imshow("Image",img)
            cv2.waitKey(1)
    def HandVolumeControl(SkipVal=10):
        wCam, hCam = 640,480


        cap = cv2.VideoCapture(0)

        cap.set(3, wCam)
        cap.set(4, hCam)
        pTime = 0
        detector = htm.handDetector(detectionCon=0.85,maxHands = 1)

        devices = AudioUtilities.GetSpeakers()
        interface = devices.Activate(
            IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
        volume = cast(interface, POINTER(IAudioEndpointVolume))
        #volume.GetMute()
        #volume.GetMasterVolumeLevel()
        volRange = volume.GetVolumeRange()
        minVol = volRange[0]
        maxVol = volRange[1]
        vol = 0
        volBar = 400
        volPer = 0
        area = 0
        colorVolume = (255,0,0)
        while True:
            success, img = cap.read()
            img = detector.findHands(img)
            lmList, bbox = detector.findPosition(img,draw = True)
            if len(lmList) != 0:
                
                #print(lmList[4][8])
                area = (bbox[2]-bbox[0] * bbox[3]-bbox[1])//100
                #print(area)
        ##        if -700<area<-1300:
        ##        print("yes")

                length, img, lineinfo = detector.findDistance(4, 8, img)
                #print(length)

                volBar = np.interp(length,[15,130],[400, 150])
                volPer = np.interp(length,[15,130],[0, 100])
                
                fingers = detector.fingersUp()
                #print(fingers)
                smoothness = SkipVal
                volPer = smoothness * round(volPer/smoothness)
                if not fingers[4]:
                    volume.SetMasterVolumeLevelScalar(volPer/100, None)
                    cv2.circle(img,(lineinfo[4],lineinfo[5]), 10, (0,255,0), cv2.FILLED)
                    colorVol = (0,255, 0)
                    time.sleep(0.25)
                else:
                    colorVol = (255,0,0)
                #print(length)

                
        ##        if length<40:
        ##            cv2.circle(img,(lineinfo[4],lineinfo[5]), 10, (0,255,0), cv2.FILLED)
            cv2.rectangle(img, (50,150), (85,400), (255, 0,0), 3)
            cv2.rectangle(img, (50, int(volBar)), (85, 400), (255, 0,0), cv2.FILLED)
            cv2.putText(img,f'{int(volPer)} %', (40,450), cv2.FONT_HERSHEY_COMPLEX,
                        1, (255, 0,0), 3)
            cVol = int(volume.GetMasterVolumeLevelScalar()*100)
            cv2.putText(img,f'Vol Set: {int(cVol)}', (400,50), cv2.FONT_HERSHEY_COMPLEX,
                        1, (255, 0,0), 3)
                    
            cTime = time.time()
            fps = 1/(cTime-pTime)
            pTime = cTime
            
            cv2.putText(img,f'FPS: {int(fps)}', (40,50), cv2.FONT_HERSHEY_COMPLEX,
                        1, (255, 0,0), 3)
            cv2.imshow("WebCam",img)
            cv2.waitKey(1)
    def bbox():
        cap = cv2.VideoCapture(0)
        detector = cvzone.HandDetector()

        while True:
            # Get image frame
            success, img = cap.read()

            # Find the hand and its landmarks
            img = detector.findHands(img, draw=False)
            lmList, bbox = detector.findPosition(img, draw=False)
            if bbox:
                # Draw  Corner Rectangle
                cvzone.cornerRect(img, bbox)

            # Display
            cv2.imshow("Image", img)
            cv2.waitKey(1)
    def dummysample():
        cap = cv2.VideoCapture(0)
        mpHands = mp.solutions.hands
        hands = mpHands.Hands()
        mpDraw = mp.solutions.drawing_utils

        pTime = 0
        cTime = 0
        while True:
            success, img = cap.read()
            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            results = hands.process(imgRGB)
            #print(results.multi_hand_landmarks)
            if results.multi_hand_landmarks:
                for handLms in results.multi_hand_landmarks:
                    for id , lm in enumerate(handLms.landmark):
                    # print(id, lm)
                        h, w, c = img.shape
                        cx, cy = int(lm.x*w), int(lm.y*h)
                        #print(id,cx, cy)
                        #if id ==4:
                        cv2.circle(img, (cx, cy), 15, (255,0,255),cv2.FILLED)
                        
                    mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)
            cTime = time.time()
            fps = 1/(cTime-pTime)
            pTime = cTime

            cv2.putText(img, str(int(fps)),(10,70), cv2.FONT_HERSHEY_PLAIN,3,
            (255,0,255), 3)
                    
            cv2.imshow("WebCam", img)
            cv2.waitKey(1)
    def Virtual_Painter(folderName,Confidence=0.65,BrushThickness=25,EraserThickness=100,WebCam=0):
        folderPath = folderName
        myList = os.listdir(folderPath)
        #print(myList)
        overlayList = []
        for imPath in myList:
            image = cv2.imread(f'{folderPath}/{imPath}')
            overlayList.append(image)
        #print(len(overlayList))
        header = overlayList[0]
        ##File path get done
        drawColor = (255,0,255)

        cap = cv2.VideoCapture(WebCam)
        cap.set(3,1280)
        cap.set(4,720)

        xp, yp = 0,0
        detector = htm1.handDetector(detectionCon=Confidence)

        brushThickness = BrushThickness
        eraserThickness = EraserThickness

        imgCanvas = np.zeros((720, 1280, 3),np.uint8)

        while True:
            success,img = cap.read()
            img = cv2.flip(img,1)
            #img = cv2.flip(img, 1)

            img = detector.findHands(img)
            lmList = detector.findPosition(img,draw=False)

            if len(lmList) != 0:
                #print(lmList)
                    
                x1,y1 = lmList[8][1:]
                x2,y2 = lmList[12][1:]
            
                fingers = detector.fingersUp()
                #print(fingers)

                if fingers[1] and fingers[2] :
                    xp, yp = 0,0
                    #print("Selection Mode")
                    if y1 <120:
                        if 90<x1<110:
                            header = overlayList[0]
                            drawColor = (255,0,255)
                        elif 220<x1<240:
                            header = overlayList[1]
                            drawColor = (240,28,28)
                        elif 350<x1<380:
                            header = overlayList[2]
                            drawColor = (0,255,0)
                        elif 460<x1<510:
                            header = overlayList[3]
                            ##(173,216,230)
                            drawColor = (230,216,173)
                        elif 570<x1<610:
                            header = overlayList[4]
                            drawColor = (0,0,255)
                        elif 700<x1<750:
                            header = overlayList[5]
                            drawColor = (0,165,255)
                        elif 790<x1<850:
                            header = overlayList[6]
                            drawColor = (0,255,255)
                        elif 1000<x1<1100:
                            header = overlayList[7]
                            drawColor = (0,0,0)
                    cv2.rectangle(img,(x1,y1-25),(x2,y2+25),drawColor,cv2.FILLED)
                    

                if fingers[1] and fingers[2]==False and fingers[3]==False and fingers[0]==False and fingers[4]==False:
                    #print("Drawing Mode")
                    cv2.circle(img, (x1,y1),brushThickness,drawColor,cv2.FILLED)

                    if xp==0 and yp==0:
                        xp,yp = x1,y1
                    if drawColor == (0,0,0):
                        cv2.line(img, (xp,yp),(x1,y1),drawColor,eraserThickness)
                        cv2.line(imgCanvas, (xp,yp),(x1,y1),drawColor,eraserThickness)
                    else:
                        cv2.line(img, (xp,yp),(x1,y1),drawColor,brushThickness)
                        cv2.line(imgCanvas, (xp,yp),(x1,y1),drawColor,brushThickness)

                    xp,yp = x1,y1
                        

            imgGray = cv2.cvtColor(imgCanvas,cv2.COLOR_BGR2GRAY)
            _, imgInv = cv2.threshold(imgGray,50,255,cv2.THRESH_BINARY_INV)
            imgInv = cv2.cvtColor(imgInv,cv2.COLOR_GRAY2BGR)
            img = cv2.bitwise_and(img,imgInv)
            img = cv2.bitwise_or(img,imgCanvas)
            
            ######setting header
            img[0:120,0:1280] = header
            #img = cv2.addWeighted(img,0.5,imgCanvas,0.5,0)
            cv2.imshow("Image",img)
            #cv2.imshow("Canvas",imgCanvas)
            #cv2.imshow("Inv",img)

            cv2.waitKey(1)

    def Virtual_Painter_b_g_r(folder):
        #vars
        brushThickness = 20
        eraserThickness = 100
        ##importtatione
        folderPath = "Header"
        myList = os.listdir(folderPath)
        #print(myList)
        overlayList = []
        for imPath in myList:
            image = cv2.imread(f'{folderPath}/{imPath}')
            overlayList.append(image)
        #print(len(overlayList))
        header = overlayList[0]
        drawColor = (255, 0, 255)
        ##webcam##
        cap = cv2.VideoCapture(0)
        cap.set(3, 1280)
        cap.set(4, 720)

        imgCanvas = np.zeros((720, 1280, 3), np.uint8)
        detector = htm1.handDetector1(detectionCon=0.7)
        xp,yp = 0,0
        while True:
            success, img = cap.read()
            img = cv2.flip(img, 1)
            img = detector.findHands(img)
            lmList = detector.findPosition(img,draw=False)

            if len(lmList) != 0:
                #print(lmList)

                
                x1, y1 = lmList[8][1:]
                x2, y2 = lmList[12][1:]

                fingers = detector.fingersUp()

                print(fingers)
                if fingers[1] and fingers[2]:
                    cv2.rectangle(img, (x1, y1-25),(x2,y2+25),drawColor,cv2.FILLED)
                    #print("Selection Mode")
                    if y1 < 120:
                        if 250<x1<450:
                            header = overlayList[0]
                            drawColor = (255,0,255)
                        elif 550<x1<750:
                            header = overlayList[1]
                            drawColor = (255,0,0)
                        elif 800<x1<950:
                            header = overlayList[2]
                            drawColor = (0,255,0)
                        elif 1050<x1<1200:
                            header = overlayList[3]
                            drawColor = (0,0,0)

                if fingers[1] and fingers[2]==False:
                    cv2.circle(img, (x1, y1),15,drawColor,cv2.FILLED)
                    #print("Drawing Mode")
                    if xp==0 and yp==0:
                        xp,yp = x1,y1
                    if drawColor == (0,0,0):
                        cv2.line(img, (xp,yp), (x1,y1),drawColor,eraserThickness)
                        cv2.line(imgCanvas, (xp,yp), (x1,y1),drawColor, eraserThickness)

                    else:
                        cv2.line(img, (xp,yp), (x1,y1),drawColor, brushThickness)
                        cv2.line(imgCanvas, (xp,yp), (x1,y1),drawColor, brushThickness)
                    xp, yp = x1,y1

            imgGray = cv2.cvtColor(imgCanvas,cv2.COLOR_BGR2GRAY)
            _, imgInv = cv2.threshold(imgGray,50,255, cv2.THRESH_BINARY_INV)
            imgInv = cv2.cvtColor(imgInv,cv2.COLOR_GRAY2BGR)
            img = cv2.bitwise_and(img,imgInv)
            img = cv2.bitwise_and(img,imgInv)
            img = cv2.bitwise_or(img, imgCanvas)

            #img = cv2.addWeighted(img,0.5,imgCanvas,0.5,0)
                            

            #Setting the header image
            img[0:125, 0:1280] = header
            cv2.waitKey(1)
            cv2.imshow("WebCam",img)
            cv2.imshow("Canvas", imgCanvas)
class Posture():
    def Posture():
        cap = cv2.VideoCapture(0)
        detector = cvzone.PoseDetector()
        while True:
            success, img = cap.read()
            img = detector.findPose(img)
            lmList = detector.findPosition(img, draw=False)
            if lmList:
                print(lmList[14])
                cv2.circle(img, (lmList[14][1], lmList[14][2]), 15, (0, 0, 255), cv2.FILLED)

            cv2.imshow("Image", img)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        cap.release()
        cv2.destroyAllWindows()
    def Trainer(Hand="Left",minangle=210,maxangle=310,halfval=False,count=0):
        Hand = "Left"

        bar = True

        minangle = 210

        maxangle = 310
        cap = cv2.VideoCapture(0)

        detector = cvzone.PoseDetector()

        count = 1

        dir = 0

        halfval = False

        pTime = 0

        val = 10

        while True:
            success, img = cap.read()
            img = cv2.resize(img,(1280,720))
            #img = cv2.imread("AiTrainer/test.jpg")
            img = detector.findPose(img,False)
            lmList = detector.findPosition(img,False)
            #print(lmList[32])
            if len(lmList) != 0:
                #Right Arm
                if Hand == "Left":
                    angle = detector.findAngle(img,11,13,15)
                    per = np.interp(angle,(minangle,maxangle),(0,100))
                    bar = np.interp(angle,(minangle,maxangle),(650, 100))
                    #print(angle,per)
                elif Hand == "Right":
                    angle = detector.findAngle(img,12,14,16)
                    per = np.interp(angle,(minangle,maxangle),(0,100))
                    bar = np.interp(angle,(minangle,maxangle),(650, 100))
                    #print(angle,per)
                color = (255,0,255)
                if per == 100:
                    color = (0,255,0)
                    if dir == 0:
                        count +=0.5
                        dir = 1
                if per == 0:
                    color = (0,255,0)
                    if dir==1:
                        count+=0.5
                        dir = 0
                #print(count)

                cv2.rectangle(img,(1100,100),(1175,650),color,3)
                cv2.rectangle(img,(1100,int(bar)),(1175,650),color, cv2.FILLED)
                cv2.putText(img,f'{int(per)} %', (1100,75), cv2.FONT_HERSHEY_PLAIN,4,
                                color,4)
                
                if count >= 1 and count < 10:
                    cv2.rectangle(img,(0,450),(250,720),(0,255,0), cv2.FILLED)
                if count >= 10 and count < 100:
                    cv2.rectangle(img,(0,450),(400,720),(0,255,0), cv2.FILLED)
                if  count >= 100 and count < 1000:
                    cv2.rectangle(img,(0,450),(600,720),(0,255,0), cv2.FILLED)
                if  count >= 1000 and count < 10000:
                    cv2.rectangle(img,(0,450),(700,720),(0,255,0), cv2.FILLED)
                    
                if halfval == False:
                    cv2.putText(img, str(int(count)), (45,670), cv2.FONT_HERSHEY_PLAIN,15,
                                (255,0,0),25)
                if halfval == True:
                    cv2.putText(img, str(count), (45,670), cv2.FONT_HERSHEY_PLAIN,15,
                                (255,0,0),25)
                cTime = time.time()
                fps = 1/(cTime-pTime)
                pTime = cTime
                cv2.putText(img, str(int(fps)), (50,100), cv2.FONT_HERSHEY_PLAIN,5,
                                (255,0,0),5)
                
            cv2.imshow("Image",img)
            cv2.waitKey(1)


class VideoExamples():
    def Stack():
        cap = cv2.VideoCapture(0)
        cap.set(3, 1280)
        cap.set(4, 720)

        while True:
            success, img = cap.read()
            imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            imgList = [img, img, imgGray, img, imgGray, img,imgGray, img, img]
            stackedImg = cvzone.stackImages(imgList, 3, 0.4)

            cv2.imshow("stackedImg", stackedImg)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        cap.release()
        cv2.destroyAllWindows()
class Face():
    def Face_Recognition(pathname,csvname):
        path = pathname
        images = []
        classNames = []
        myList = os.listdir(path)
        print(myList)
        for cl in myList:
            curImg = cv2.imread(f'{path}/{cl}')
            images.append(curImg)
            classNames.append(os.path.splitext(cl)[0])
        print(classNames)

        def findEncodings(images):
            encodeList = []
            for img in images:
                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
                encode = fr.face_encodings(img)[0]
                encodeList.append(encode)
            return encodeList

        def markAttendance(name):
            with open(csvname,'r+')as f:
                myDataList = f.readlines()
                nameList = []
                for line in myDataList:
                    entry = line.split(',')
                    nameList.append(entry[0])
        ##        if name not in nameList: #####U can use this and indent the next 3 lines once if you want a name to be there only once
                now = datetime.now()
                dtString = now.strftime('%H:%M:%S')
                f.writelines(f'\n{name},{dtString}')
                    
            

        encodeListKnown = findEncodings(images)
        print('Encoding Complete')

        cap = cv2.VideoCapture(0)

        while True:
            success, img = cap.read()
            imgS = cv2.resize(img,(0,0),None,0.25,0.25)
            imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)
            
            facesCurFrame = fr.face_locations(imgS)           
            encodesCurFrame = fr.face_encodings(imgS,facesCurFrame)

            for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):
                matches = fr.compare_faces(encodeListKnown,encodeFace)
                faceDis = fr.face_distance(encodeListKnown,encodeFace)
                #print(faceDis)
                matchIndex = np.argmin(faceDis)

                if matches[matchIndex]:
                    name = classNames[matchIndex].upper()
                    #print(name)
                    y1,x2,y2,x1 = faceLoc
                    y1,x2,y2,x1 = y1*4,x2*4,y2*4,x1*4
                    cv2.rectangle(img,(x1,y1),(x2,y2),(0,0,255),2)
                    cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,0,255),cv2.FILLED)
                    cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)
                    markAttendance(name)

                cv2.imshow('Webcam',img)
                cv2.waitKey(1)

                
                
            

        ##faceLoc = fr.face_locations(imgElon)[0]
        ##encodeElon = fr.face_encodings(imgElon)[0]
        ###print(faceLoc)
        ##cv2.rectangle(imgElon,(faceLoc[3],faceLoc[0]),(faceLoc[1],faceLoc[2]),(255,0,255),2)
        ##
        ##faceLocTest = fr.face_locations(imgTest)[0]
        ##encodeTest = fr.face_encodings(imgTest)[0]
        ###print(faceLoc)
        ##cv2.rectangle(imgTest,(faceLocTest[3],faceLocTest[0]),(faceLocTest[1],faceLocTest[2]),(255,0,255),2)
        ##
        ##results = fr.compare_faces([encodeElon],encodeTest)
        ##faceDis = fr.face_distance([encodeElon],encodeTest)
                

        ##imgElon = fr.load_image_file("ImagesBasic/elon musk.jpg")
        ##imgElon = cv2.cvtColor(imgElon,cv2.COLOR_BGR2RGB)
        ##imgTest = fr.load_image_file("ImagesBasic/bill gates.jpg")
        ##imgTest = cv2.cvtColor(imgTest,cv2.COLOR_BGR2RGB)
    def face_percent_detection():
        cap = cv2.VideoCapture(0)
        detector = cvzone.FaceDetector()

        while True:
            success, img = cap.read()
            img, bboxs = detector.findFaces(img)
            #print(bboxs)
            cv2.imshow("Image", img)
            cv2.waitKey(1)
    def face_mesh_detection():
        cap = cv2.VideoCapture(0)
        detector = cvzone.FaceMeshDetector(maxFaces=2)
        while True:
            success, img = cap.read()
            img, faces = detector.findFaceMesh(img)
            if faces:
                print(faces[0])
            cv2.imshow("Image", img)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        cap.release()
        cv2.destroyAllWindows()
class Object():
    def Recognize(confidence=0.65,outputname="Webcam"):
        thres = confidence
        cap = cv2.VideoCapture(0)
        cap.set(3,640)
        cap.set(4,480)


        classNames = []
        classFile = 'Objects/coco.names'
        with open(classFile,'rt') as f:
            classNames = f.read().rstrip('\n').split('\n')

        configPath = 'Objects/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'
        weightsPath = 'Objects/frozen_inference_graph.pb'

        net = cv2.dnn_DetectionModel(weightsPath,configPath)
        net.setInputSize(320,320)
        net.setInputScale(1.0/ 127.5)
        net.setInputMean((127.5, 127.5, 127.5))
        net.setInputSwapRB(True)

        while True:
            success,img = cap.read()
            classIds, confs, bbox = net.detect(img,confThreshold=thres)
            #print(classIds,bbox)
            if len(classIds) != 0:
                for classId, confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):
                    cv2.rectangle(img,box,color=(0,255,0),thickness=2)
                    cv2.putText(img,classNames[classId-1].upper(),(box[0]+10,box[1]+30),
                                cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)
                    cv2.putText(img,str(round(confidence*100,2)),(box[0]+200,box[1]+30),
                                cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)

            cv2.imshow(outputname,img)
            cv2.waitKey(1)
