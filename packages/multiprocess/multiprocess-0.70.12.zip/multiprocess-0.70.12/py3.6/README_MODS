cp -rf Python-3.6.0/Modules/_multiprocessing Modules/_multiprocessing
cp -rf Python-3.6.0/Lib/multiprocessing multiprocessing
cp -rf Python-3.6.0/Lib/test/*test_multiprocessing*.py multiprocess/tests/
cp -rf py3.5/examples .
cp -f py3.5/setup.py .
cp -rf py3.5/doc .
cp -f py3.5/index.html .
cp Python-3.6.13/Lib/test/mp_*py multiprocess/tests
cp Python-3.6.13/Lib/test/_test_multiprocessing.py tests/__init__.py

# ----------------------------------------------------------------------
diff Modules/_multiprocess/multiprocess.c Python-3.6.0/Modules/_multiprocessing/multiprocessing.c 
10c10
< #include "multiprocess.h"
---
> #include "multiprocessing.h"
144c144
<     "_multiprocess",
---
>     "_multiprocessing",
156c156
< PyInit__multiprocess(void)
---
> PyInit__multiprocessing(void)

diff Modules/_multiprocess/semaphore.c Python-3.6.0/Modules/_multiprocessing/semaphore.c      
10c10
< #include "multiprocess.h"
---
> #include "multiprocessing.h"
201c201
< // ifndef HAVE_SEM_TIMEDWAIT
---
> #ifndef HAVE_SEM_TIMEDWAIT
262c262
< // endif /* !HAVE_SEM_TIMEDWAIT */
---
> #endif /* !HAVE_SEM_TIMEDWAIT */
616c616
<     /* tp_name           */ "_multiprocess.SemLock",
---
>     /* tp_name           */ "_multiprocessing.SemLock",

diff multiprocess/__init__.py Python-3.6.0/Lib/multiprocessing/__init__.py
18,19d17
< __version__ = '0.70.5.dev0'
< 

diff multiprocess/connection.py Python-3.6.0/Lib/multiprocessing/connection.py
21,24c21
< try:
<     import _multiprocess as _multiprocessing
< except ImportError:
<     import _multiprocessing
---
> import _multiprocessing

diff multiprocess/forkserver.py Python-3.6.0/Lib/multiprocessing/forkserver.py
95c95
<             cmd = ('from multiprocess.forkserver import main; ' +
---
>             cmd = ('from multiprocessing.forkserver import main; ' +

diff multiprocess/popen_fork.py Python-3.6.0/Lib/multiprocessing/popen_fork.py
47c47
<                 from multiprocess.connection import wait
---
>                 from multiprocessing.connection import wait

diff multiprocess/popen_forkserver.py Python-3.6.0/Lib/multiprocessing/popen_forkserver.py
60c60
<             from multiprocess.connection import wait
---
>             from multiprocessing.connection import wait

diff multiprocess/queues.py Python-3.6.0/Lib/multiprocessing/queues.py
22,25c22
< try:
<     import _multiprocess as _multiprocessing
< except ImportError:
<     import _multiprocessing
---
> import _multiprocessing

diff multiprocess/reduction.py Python-3.6.0/Lib/multiprocessing/reduction.py
14,17c14
< try:
<     import dill as pickle
< except ImportError:
<     import pickle
---
> import pickle

diff multiprocess/semaphore_tracker.py Python-3.6.0/Lib/multiprocessing/semaphore_tracker.py
19,22c19
< try:
<     import _multiprocess as _multiprocessing
< except ImportError:
<     import _multiprocessing
---
> import _multiprocessing
53c50
<             cmd = 'from multiprocess.semaphore_tracker import main;main(%d)'
---
>             cmd = 'from multiprocessing.semaphore_tracker import main;main(%d)'

diff multiprocess/spawn.py Python-3.6.0/Lib/multiprocessing/spawn.py
89c86
<         prog = 'from multiprocess.spawn import spawn_main; spawn_main(%s)'
---
>         prog = 'from multiprocessing.spawn import spawn_main; spawn_main(%s)'

diff multiprocess/synchronize.py Python-3.6.0/Lib/multiprocessing/synchronize.py
17,20c17
< try:
<     import _multiprocess as _multiprocessing
< except ImportError:
<     import _multiprocessing
---
> import _multiprocessing
32,40c29,34
<     from _multiprocess import SemLock, sem_unlink
< except ImportError:
<     try:
<         from _multiprocessing import SemLock, sem_unlink
<     except (ImportError):
<         raise ImportError("This platform lacks a functioning sem_open" +
<                           " implementation, therefore, the required" +
<                           " synchronization primitives needed will not" +
<                           " function, see issue 3770.")
---
>     from _multiprocessing import SemLock, sem_unlink
> except (ImportError):
>     raise ImportError("This platform lacks a functioning sem_open" +
>                       " implementation, therefore, the required" +
>                       " synchronization primitives needed will not" +
>                       " function, see issue 3770.")

diff multiprocess/util.py Python-3.6.0/Lib/multiprocessing/util.py
38c38
< LOGGER_NAME = 'multiprocess'
---
> LOGGER_NAME = 'multiprocessing'

# ----------------------------------------------------------------------
REPLACED "from multiprocessing" with "from multiprocess"
REPLACED "from _multiprocessing" with "from _multiprocess"
REPLACED "import _multiprocessing" with "import _multiprocess as _multiprocessing"
REPLACED "multprocessing" with "multiprocess" wherever else relevant...
# ----------------------------------------------------------------------
diff Python-3.6.0/Lib/multiprocessing/context.py Python-3.6.6rc1/Lib/multiprocessing/context.py
199c199
<     def set_start_method(self, method=None):
---
>     def set_start_method(self, method, force=False):
Common subdirectories: Python-3.6.0/Lib/multiprocessing/dummy and Python-3.6.6rc1/Lib/multiprocessing/dummy
diff Python-3.6.0/Lib/multiprocessing/forkserver.py Python-3.6.6rc1/Lib/multiprocessing/forkserver.py
35a36
>         self._forkserver_pid = None
92,93c93,103
<             if self._forkserver_alive_fd is not None:
<                 return
---
>             if self._forkserver_pid is not None:
>                 # forkserver was launched before, is it still running?
>                 pid, status = os.waitpid(self._forkserver_pid, os.WNOHANG)
>                 if not pid:
>                     # still alive
>                     return
>                 # dead, launch it again
>                 os.close(self._forkserver_alive_fd)
>                 self._forkserver_address = None
>                 self._forkserver_alive_fd = None
>                 self._forkserver_pid = None
129a140
>                 self._forkserver_pid = pid
152,153c163,171
<     # ignoring SIGCHLD means no need to reap zombie processes
<     handler = signal.signal(signal.SIGCHLD, signal.SIG_IGN)
---
>     handlers = {
>         # no need to reap zombie processes;
>         signal.SIGCHLD: signal.SIG_IGN,
>         # protect the process from ^C
>         signal.SIGINT: signal.SIG_IGN,
>         }
>     old_handlers = {sig: signal.signal(sig, val)
>                     for (sig, val) in handlers.items()}
> 
178c196
<                             _serve_one(s, listener, alive_r, handler)
---
>                             _serve_one(s, listener, alive_r, old_handlers)
189,190c207,208
< def _serve_one(s, listener, alive_r, handler):
<     # close unnecessary stuff and reset SIGCHLD handler
---
> def _serve_one(s, listener, alive_r, handlers):
>     # close unnecessary stuff and reset signal handlers
193c211,212
<     signal.signal(signal.SIGCHLD, handler)
---
>     for sig, val in handlers.items():
>         signal.signal(sig, val)
diff Python-3.6.0/Lib/multiprocessing/pool.py Python-3.6.6rc1/Lib/multiprocessing/pool.py
121c121
<             if wrap_exception:
---
>             if wrap_exception and func is not _helper_reraises_exception:
130a131,132
> 
>         task = job = result = func = args = kwds = None
133a136,139
> def _helper_reraises_exception(ex):
>     'Pickle-able helper function for use by _guarded_task_generation.'
>     raise ex
> 
277a284,294
>     def _guarded_task_generation(self, result_job, func, iterable):
>         '''Provides a generator of tasks for imap and imap_unordered with
>         appropriate handling for iterables which throw exceptions during
>         iteration.'''
>         try:
>             i = -1
>             for i, x in enumerate(iterable):
>                 yield (result_job, i, func, (x,), {})
>         except Exception as e:
>             yield (result_job, i+1, _helper_reraises_exception, (e,), {})
> 
286,287c303,307
<             self._taskqueue.put((((result._job, i, func, (x,), {})
<                          for i, x in enumerate(iterable)), result._set_length))
---
>             self._taskqueue.put(
>                 (
>                     self._guarded_task_generation(result._job, func, iterable),
>                     result._set_length
>                 ))
293,294c313,319
<             self._taskqueue.put((((result._job, i, mapstar, (x,), {})
<                      for i, x in enumerate(task_batches)), result._set_length))
---
>             self._taskqueue.put(
>                 (
>                     self._guarded_task_generation(result._job,
>                                                   mapstar,
>                                                   task_batches),
>                     result._set_length
>                 ))
305,306c330,334
<             self._taskqueue.put((((result._job, i, func, (x,), {})
<                          for i, x in enumerate(iterable)), result._set_length))
---
>             self._taskqueue.put(
>                 (
>                     self._guarded_task_generation(result._job, func, iterable),
>                     result._set_length
>                 ))
312,313c340,346
<             self._taskqueue.put((((result._job, i, mapstar, (x,), {})
<                      for i, x in enumerate(task_batches)), result._set_length))
---
>             self._taskqueue.put(
>                 (
>                     self._guarded_task_generation(result._job,
>                                                   mapstar,
>                                                   task_batches),
>                     result._set_length
>                 ))
324c357
<         self._taskqueue.put(([(result._job, None, func, args, kwds)], None))
---
>         self._taskqueue.put(([(result._job, 0, func, args, kwds)], None))
355,356c388,395
<         self._taskqueue.put((((result._job, i, mapper, (x,), {})
<                               for i, x in enumerate(task_batches)), None))
---
>         self._taskqueue.put(
>             (
>                 self._guarded_task_generation(result._job,
>                                               mapper,
>                                               task_batches),
>                 None
>             )
>         )
378d416
<             i = -1
380c418,419
<                 for i, task in enumerate(taskseq):
---
>                 # iterating taskseq cannot fail
>                 for task in taskseq:
387c426
<                         job, ind = task[:2]
---
>                         job, idx = task[:2]
389c428
<                             cache[job]._set(ind, (False, e))
---
>                             cache[job]._set(idx, (False, e))
395c434,435
<                         set_length(i+1)
---
>                         idx = task[1] if task else -1
>                         set_length(idx + 1)
398,404c438,439
<             except Exception as ex:
<                 job, ind = task[:2] if task else (0, 0)
<                 if job in cache:
<                     cache[job]._set(ind + 1, (False, ex))
<                 if set_length:
<                     util.debug('doing set_length()')
<                     set_length(i+1)
---
>             finally:
>                 task = taskseq = job = None
408d442
< 
447a482
>             task = job = obj = None
463a499
>             task = job = obj = None
diff Python-3.6.0/Lib/multiprocessing/popen_fork.py Python-3.6.6rc1/Lib/multiprocessing/popen_fork.py
17,18c17
<         sys.stdout.flush()
<         sys.stderr.flush()
---
>         util._flush_std_streams()
diff Python-3.6.0/Lib/multiprocessing/process.py Python-3.6.6rc1/Lib/multiprocessing/process.py
106a107,109
>         # Avoid a refcycle if the target function holds an indirect
>         # reference to the process object (see bpo-30775)
>         del self._target, self._args, self._kwargs
131a135
> 
134,135c138,144
<         self._popen.poll()
<         return self._popen.returncode is None
---
> 
>         returncode = self._popen.poll()
>         if returncode is None:
>             return True
>         else:
>             _children.discard(self)
>             return False
268,269c277
<             sys.stdout.flush()
<             sys.stderr.flush()
---
>             util._flush_std_streams()
diff Python-3.6.0/Lib/multiprocessing/queues.py Python-3.6.6rc1/Lib/multiprocessing/queues.py
104c104
<                     if timeout < 0 or not self._poll(timeout):
---
>                     if not self._poll(timeout):
172,179c172
<         # On process exit we will wait for data to be flushed to pipe.
<         #
<         # However, if this process created the queue then all
<         # processes which use the queue will be descendants of this
<         # process.  Therefore waiting for the queue to be flushed
<         # is pointless once all the child processes have been joined.
<         created_by_this_process = (self._opid == os.getpid())
<         if not self._joincancelled and not created_by_this_process:
---
>         if not self._joincancelled:
224,225c217,218
<         try:
<             while 1:
---
>         while 1:
>             try:
252,259c245,251
<         except Exception as e:
<             if ignore_epipe and getattr(e, 'errno', 0) == errno.EPIPE:
<                 return
<             # Since this runs in a daemon thread the resources it uses
<             # may be become unusable while the process is cleaning up.
<             # We ignore errors which happen after the process has
<             # started to cleanup.
<             try:
---
>             except Exception as e:
>                 if ignore_epipe and getattr(e, 'errno', 0) == errno.EPIPE:
>                     return
>                 # Since this runs in a daemon thread the resources it uses
>                 # may be become unusable while the process is cleaning up.
>                 # We ignore errors which happen after the process has
>                 # started to cleanup.
261a254
>                     return
265,266d257
<             except Exception:
<                 pass
339a331
>         self._poll = self._reader.poll
diff Python-3.6.0/Lib/multiprocessing/semaphore_tracker.py Python-3.6.6rc1/Lib/multiprocessing/semaphore_tracker.py
31a32
>         self._pid = None
43,44c44,57
<             if self._fd is not None:
<                 return
---
>             if self._pid is not None:
>                 # semaphore tracker was launched before, is it still running?
>                 pid, status = os.waitpid(self._pid, os.WNOHANG)
>                 if not pid:
>                     # => still alive
>                     return
>                 # => dead, launch it again
>                 os.close(self._fd)
>                 self._fd = None
>                 self._pid = None
> 
>                 warnings.warn('semaphore_tracker: process died unexpectedly, '
>                               'relaunching.  Some semaphores might leak.')
> 
58c71
<                 util.spawnv_passfds(exe, args, fds_to_pass)
---
>                 pid = util.spawnv_passfds(exe, args, fds_to_pass)
63a77
>                 self._pid = pid
diff Python-3.6.0/Lib/multiprocessing/spawn.py Python-3.6.6rc1/Lib/multiprocessing/spawn.py
220c220
<         set_start_method(data['start_method'])
---
>         set_start_method(data['start_method'], force=True)
diff Python-3.6.0/Lib/multiprocessing/util.py Python-3.6.6rc1/Lib/multiprocessing/util.py
244c244
<         f = lambda p : p[0][0] is not None
---
>         f = lambda p : p[0] is not None
246c246
<         f = lambda p : p[0][0] is not None and p[0][0] >= minpriority
---
>         f = lambda p : p[0] is not None and p[0] >= minpriority
248,249c248,249
<     items = [x for x in list(_finalizer_registry.items()) if f(x)]
<     items.sort(reverse=True)
---
>     # Careful: _finalizer_registry may be mutated while this function
>     # is running (either by a GC run or by another thread).
251,257c251,265
<     for key, finalizer in items:
<         sub_debug('calling %s', finalizer)
<         try:
<             finalizer()
<         except Exception:
<             import traceback
<             traceback.print_exc()
---
>     # list(_finalizer_registry) should be atomic, while
>     # list(_finalizer_registry.items()) is not.
>     keys = [key for key in list(_finalizer_registry) if f(key)]
>     keys.sort(reverse=True)
> 
>     for key in keys:
>         finalizer = _finalizer_registry.get(key)
>         # key may have been removed from the registry
>         if finalizer is not None:
>             sub_debug('calling %s', finalizer)
>             try:
>                 finalizer()
>             except Exception:
>                 import traceback
>                 traceback.print_exc()
383a392,405
> # Flush standard streams, if any
> #
> 
> def _flush_std_streams():
>     try:
>         sys.stdout.flush()
>     except (AttributeError, ValueError):
>         pass
>     try:
>         sys.stderr.flush()
>     except (AttributeError, ValueError):
>         pass
> 
> #
389c411
<     passfds = sorted(passfds)
---
>     passfds = tuple(sorted(map(int, passfds)))
# ----------------------------------------------------------------------
diff Python-3.6.6rc1/Modules/_multiprocessing/semaphore.c Python-3.6.8/Modules/_multiprocessing/semaphore.c
442,443c442,444
<         if (name_copy == NULL)
<             goto failure;
---
>         if (name_copy == NULL) {
>             return PyErr_NoMemory();
>         }
466c467,469
<     _PyMp_SetError(NULL, MP_STANDARD_ERROR);
---
>     if (!PyErr_Occurred()) {
>         _PyMp_SetError(NULL, MP_STANDARD_ERROR);
>     }
diff Python-3.6.6rc1/Lib/multiprocessing/connection.py Python-3.6.8/Lib/multiprocessing/connection.py
60c60
<     return time.time() + timeout
---
>     return time.monotonic() + timeout
63c63
<     return time.time() > t
---
>     return time.monotonic() > t
908c908
<                 deadline = time.time() + timeout
---
>                 deadline = time.monotonic() + timeout
916c916
<                         timeout = deadline - time.time()
---
>                         timeout = deadline - time.monotonic()
Common subdirectories: Python-3.6.6rc1/Lib/multiprocessing/dummy and Python-3.6.8/Lib/multiprocessing/dummy
diff Python-3.6.6rc1/Lib/multiprocessing/managers.py Python-3.6.8/Lib/multiprocessing/managers.py
20a21
> import time
22d22
< from time import time as _time
1009c1009
<             endtime = _time() + timeout
---
>             endtime = time.monotonic() + timeout
1015c1015
<                 waittime = endtime - _time()
---
>                 waittime = endtime - time.monotonic()
1098c1098
<     '__contains__', '__delitem__', '__getitem__', '__len__',
---
>     '__contains__', '__delitem__', '__getitem__', '__iter__', '__len__',
1101a1102,1104
> DictProxy._method_to_typeid_ = {
>     '__iter__': 'Iterator',
>     }
diff Python-3.6.6rc1/Lib/multiprocessing/queues.py Python-3.6.8/Lib/multiprocessing/queues.py
98c98
<                 deadline = time.time() + timeout
---
>                 deadline = time.monotonic() + timeout
103c103
<                     timeout = deadline - time.time()
---
>                     timeout = deadline - time.monotonic()
diff Python-3.6.6rc1/Lib/multiprocessing/reduction.py Python-3.6.8/Lib/multiprocessing/reduction.py
153c153
<         msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_LEN(bytes_size))
---
>         msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_SPACE(bytes_size))
diff Python-3.6.6rc1/Lib/multiprocessing/synchronize.py Python-3.6.8/Lib/multiprocessing/synchronize.py
18,19c18
< 
< from time import time as _time
---
> import time
316c315
<             endtime = _time() + timeout
---
>             endtime = time.monotonic() + timeout
322c321
<                 waittime = endtime - _time()
---
>                 waittime = endtime - time.monotonic()
diff Python-3.6.6rc1/Lib/test/test_multiprocessing_fork.py Python-3.6.8/Lib/test/test_multiprocessing_fork.py 
3a4
> import sys
8a10,14
> if sys.platform == "win32":
>     raise unittest.SkipTest("fork is not available on Windows")
> 
> if sys.platform == 'darwin':
>     raise unittest.SkipTest("test may crash on macOS (bpo-33725)")
diff Python-3.6.6rc1/Lib/test/test_multiprocessing_forkserver.py Python-3.6.8/Lib/test/test_multiprocessing_forkserver.py 
3a4
> import sys
8a10,12
> if sys.platform == "win32":
>     raise unittest.SkipTest("forkserver is not available on Windows")
> 
diff Python-3.6.6rc1/Lib/test/test_multiprocessing_main_handling.py Python-3.6.8/Lib/test/test_multiprocessing_main_handling.py 
61c61
<     deadline = time.time() + 10 # up to 10 s to report the results
---
>     start_time = time.monotonic()
64,65c64,67
<         if time.time() > deadline:
<             raise RuntimeError("Timed out waiting for results")
---
>         # up to 1 min to report the results
>         dt = time.monotonic() - start_time
>         if dt > 60.0:
>             raise RuntimeError("Timed out waiting for results (%.1f sec)" % dt)
89c91
< deadline = time.time() + 10 # up to 10 s to report the results
---
> start_time = time.monotonic()
92,93c94,97
<     if time.time() > deadline:
<         raise RuntimeError("Timed out waiting for results")
---
>     # up to 1 min to report the results
>     dt = time.monotonic() - start_time
>     if dt > 60.0:
>         raise RuntimeError("Timed out waiting for results (%.1f sec)" % dt)
# ----------------------------------------------------------------------
ADDED *args, **kwds for ForkingPickler in __init__, dump, and dumps
# ----------------------------------------------------------------------
diff Python-3.6.13/Lib/test/_test_multiprocessing.py tests/__init__.py 
2c2
< # Unit tests for the multiprocessing package
---
> # Unit tests for the multiprocess package
30c30
< support.import_module('multiprocessing.synchronize')
---
> support.import_module('multiprocess.synchronize')
36,41c36,41
< import multiprocessing.connection
< import multiprocessing.dummy
< import multiprocessing.heap
< import multiprocessing.managers
< import multiprocessing.pool
< import multiprocessing.queues
---
> import multiprocess.connection
> import multiprocess.dummy
> import multiprocess.heap
> import multiprocess.managers
> import multiprocess.pool
> import multiprocess.queues
43c43
< from multiprocessing import util
---
> from multiprocess import util
46c46
<     from multiprocessing import reduction
---
>     from multiprocess import reduction
52c52
<     from multiprocessing.sharedctypes import Value, copy
---
>     from multiprocess.sharedctypes import Value, copy
71c71
<     if isinstance(queue, multiprocessing.queues.Queue):
---
>     if isinstance(queue, multiprocess.queues.Queue):
98c98
< from multiprocessing.connection import wait
---
> from multiprocess.connection import wait
111c111
< PRELOAD = ['__main__', 'test.test_multiprocessing_forkserver']
---
> PRELOAD = ['__main__', 'test_multiprocessing_forkserver']
347c347
<             cpus = multiprocessing.cpu_count()
---
>             cpus = multiprocess.cpu_count()
376a377
>     @unittest.skipIf(True, "fails with is_dill(obj, child=True)")
488c489
<         sm = multiprocessing.get_start_method()
---
>         sm = multiprocess.get_start_method()
494c495
<         from multiprocessing.forkserver import _forkserver
---
>         from multiprocess.forkserver import _forkserver
534c535
< class _UpperCaser(multiprocessing.Process):
---
> class _UpperCaser(multiprocess.Process):
537,538c538,539
<         multiprocessing.Process.__init__(self)
<         self.child_conn, self.parent_conn = multiprocessing.Pipe()
---
>         multiprocess.Process.__init__(self)
>         self.child_conn, self.parent_conn = multiprocess.Pipe()
583c584
<             self.assertIn("test_multiprocessing.py", err)
---
>             self.assertIn("__init__.py", err)
864c865
<                     import multiprocessing
---
>                     import multiprocess as multiprocessing
881c882
<         q = multiprocessing.Queue()
---
>         q = multiprocess.Queue()
1286,1287c1287,1288
<         wrapper = multiprocessing.heap.BufferWrapper(struct.calcsize('i'))
<         lock = multiprocessing.Lock()
---
>         wrapper = multiprocess.heap.BufferWrapper(struct.calcsize('i'))
>         lock = multiprocess.Lock()
1642c1643
<             self.skipTest("requires multiprocessing.sharedctypes")
---
>             self.skipTest("requires multiprocess.sharedctypes")
1826c1827
<     def test_list_proxy_in_list(self):
---
>     def _test_list_proxy_in_list(self):
1869c1870
<     def test_dict_proxy_nested(self):
---
>     def _test_dict_proxy_nested(self):
2008c2009
<     def test_map_async_callbacks(self):
---
>     def _test_map_async_callbacks(self):
2034c2035
<         except multiprocessing.TimeoutError:
---
>         except multiprocess.TimeoutError:
2072c2073
<         self.assertRaises(multiprocessing.TimeoutError, get, timeout=TIMEOUT2)
---
>         self.assertRaises(multiprocess.TimeoutError, get, timeout=TIMEOUT2)
2208a2210
>     @unittest.skipIf(True, "fails with is_dill(obj, child=True)")
2224c2226
<             self.assertIs(type(cause), multiprocessing.pool.RemoteTraceback)
---
>             self.assertIs(type(cause), multiprocess.pool.RemoteTraceback)
2250a2253
>     @unittest.skipIf(True, "fails with is_dill(obj, child=True)")
2258c2261
<     def test_map_no_failfast(self):
---
>     def _test_map_no_failfast(self):
2303c2306
<         p = multiprocessing.Pool(2)
---
>         p = multiprocess.Pool(2)
2317,2319c2320,2322
<     def test_unpickleable_result(self):
<         from multiprocessing.pool import MaybeEncodingError
<         p = multiprocessing.Pool(2)
---
>     def _test_unpickleable_result(self):
>         from multiprocess.pool import MaybeEncodingError
>         p = multiprocess.Pool(2)
2343c2346
<         p = multiprocessing.Pool(3, maxtasksperchild=10)
---
>         p = multiprocess.Pool(3, maxtasksperchild=10)
2374c2377
<         p = multiprocessing.Pool(3, maxtasksperchild=1)
---
>         p = multiprocess.Pool(3, maxtasksperchild=1)
2388c2391
< from multiprocessing.managers import BaseManager, BaseProxy, RemoteError
---
> from multiprocess.managers import BaseManager, BaseProxy, RemoteError
2636c2639
<             except multiprocessing.BufferTooShort as e:
---
>             except multiprocess.BufferTooShort as e:
2764c2767
<     @unittest.skipUnless(HAS_REDUCTION, "test needs multiprocessing.reduction")
---
>     @unittest.skipUnless(HAS_REDUCTION, "test needs multiprocess.reduction")
2783c2786
<     @unittest.skipUnless(HAS_REDUCTION, "test needs multiprocessing.reduction")
---
>     @unittest.skipUnless(HAS_REDUCTION, "test needs multiprocess.reduction")
2820c2823
<     @unittest.skipUnless(HAS_REDUCTION, "test needs multiprocessing.reduction")
---
>     @unittest.skipUnless(HAS_REDUCTION, "test needs multiprocess.reduction")
3002c3005
< @unittest.skipUnless(HAS_REDUCTION, "test needs multiprocessing.reduction")
---
> @unittest.skipUnless(HAS_REDUCTION, "test needs multiprocess.reduction")
3009c3012
<         from multiprocessing import resource_sharer
---
>         from multiprocess import resource_sharer
3151c3154
<             b = multiprocessing.heap.BufferWrapper(size)
---
>             b = multiprocess.heap.BufferWrapper(size)
3158c3161
<         heap = multiprocessing.heap.BufferWrapper._heap
---
>         heap = multiprocess.heap.BufferWrapper._heap
3198,3199c3201,3202
<             a = multiprocessing.heap.BufferWrapper(1)
<             b = multiprocessing.heap.BufferWrapper(1)
---
>             a = multiprocess.heap.BufferWrapper(1)
>             b = multiprocess.heap.BufferWrapper(1)
3220c3223
<             self.skipTest("requires multiprocessing.sharedctypes")
---
>             self.skipTest("requires multiprocess.sharedctypes")
3312c3315
<         # call multiprocessing's cleanup function then exit process without
---
>         # call multiprocess's cleanup function then exit process without
3392c3395
<         folder = os.path.dirname(multiprocessing.__file__)
---
>         folder = os.path.dirname(multiprocess.__file__)
3396,3398c3399,3401
<         modules = ['multiprocessing.' + m for m in modules]
<         modules.remove('multiprocessing.__init__')
<         modules.append('multiprocessing')
---
>         modules = ['multiprocess.' + m for m in modules]
>         modules.remove('multiprocess.__init__')
>         modules.append('multiprocess')
3404,3406c3407,3409
<             modules.remove('multiprocessing.popen_fork')
<             modules.remove('multiprocessing.popen_forkserver')
<             modules.remove('multiprocessing.popen_spawn_posix')
---
>             modules.remove('multiprocess.popen_fork')
>             modules.remove('multiprocess.popen_forkserver')
>             modules.remove('multiprocess.popen_spawn_posix')
3408c3411
<             modules.remove('multiprocessing.popen_spawn_win32')
---
>             modules.remove('multiprocess.popen_spawn_win32')
3410c3413
<                 modules.remove('multiprocessing.popen_forkserver')
---
>                 modules.remove('multiprocess.popen_forkserver')
3414c3417
<             modules.remove('multiprocessing.sharedctypes')
---
>             modules.remove('multiprocess.sharedctypes')
3436c3439
<         logger = multiprocessing.get_logger()
---
>         logger = multiprocess.get_logger()
3445c3448
<         logger = multiprocessing.get_logger()
---
>         logger = multiprocess.get_logger()
3452c3455
<         logger = multiprocessing.get_logger()
---
>         logger = multiprocess.get_logger()
3456c3459
<         reader, writer = multiprocessing.Pipe(duplex=False)
---
>         reader, writer = multiprocess.Pipe(duplex=False)
3478c3481
< #         assert record.processName == multiprocessing.current_process().name
---
> #         assert record.processName == multiprocess.current_process().name
3487c3490
< #                 'multiprocessing.test.TestLoggingProcessName')
---
> #                 'multiprocess.test.TestLoggingProcessName')
3536c3539
<         conn = multiprocessing.connection.Connection(44977608)
---
>         conn = multiprocess.connection.Connection(44977608)
3547c3550
<                           multiprocessing.connection.Connection, -1)
---
>                           multiprocess.connection.Connection, -1)
3559,3560c3562,3563
<         self.assertRaises(multiprocessing.AuthenticationError,
<                           multiprocessing.connection.deliver_challenge,
---
>         self.assertRaises(multiprocess.AuthenticationError,
>                           multiprocess.connection.deliver_challenge,
3570c3573
<                     return multiprocessing.connection.CHALLENGE
---
>                     return multiprocess.connection.CHALLENGE
3576,3577c3579,3580
<         self.assertRaises(multiprocessing.AuthenticationError,
<                           multiprocessing.connection.answer_challenge,
---
>         self.assertRaises(multiprocess.AuthenticationError,
>                           multiprocess.connection.answer_challenge,
3589c3592
<         self.mgr = multiprocessing.Manager()
---
>         self.mgr = multiprocess.Manager()
3598c3601
<         m = multiprocessing.managers.SyncManager()
---
>         m = multiprocess.managers.SyncManager()
3606,3607c3609,3610
<         self.assertRaises(TypeError, multiprocessing.Pool, initializer=1)
<         p = multiprocessing.Pool(1, initializer, (self.ns,))
---
>         self.assertRaises(TypeError, multiprocess.Pool, initializer=1)
>         p = multiprocess.Pool(1, initializer, (self.ns,))
3624,3625c3627,3628
<     queue = multiprocessing.Queue()
<     subProc = multiprocessing.Process(target=_this_sub_process, args=(queue,))
---
>     queue = multiprocess.Queue()
>     subProc = multiprocess.Process(target=_this_sub_process, args=(queue,))
3634c3637
<     pool = multiprocessing.Pool(processes=4)
---
>     pool = multiprocess.Pool(processes=4)
3663c3666
<         proc = multiprocessing.Process(target=_test_process)
---
>         proc = multiprocess.Process(target=_test_process)
3668c3671
<         p = multiprocessing.Process(target=pool_in_process)
---
>         p = multiprocess.Process(target=pool_in_process)
3676c3679
<         proc = multiprocessing.Process(target=lambda: flike.flush())
---
>         proc = multiprocess.Process(target=lambda: flike.flush())
3692c3695
<         from multiprocessing.connection import wait
---
>         from multiprocess.connection import wait
3698,3699c3701,3702
<             r, w = multiprocessing.Pipe(duplex=False)
<             p = multiprocessing.Process(target=self._child_test_wait, args=(w, slow))
---
>             r, w = multiprocess.Pipe(duplex=False)
>             p = multiprocess.Process(target=self._child_test_wait, args=(w, slow))
3732c3735
<         from multiprocessing.connection import wait
---
>         from multiprocess.connection import wait
3742c3745
<             p = multiprocessing.Process(target=self._child_test_wait_socket,
---
>             p = multiprocess.Process(target=self._child_test_wait_socket,
3775c3778
<         from multiprocessing.connection import wait
---
>         from multiprocess.connection import wait
3778c3781
<         a, b = multiprocessing.Pipe()
---
>         a, b = multiprocess.Pipe()
3803c3806
<         from multiprocessing.connection import wait
---
>         from multiprocess.connection import wait
3807,3809c3810,3812
<         sem = multiprocessing.Semaphore(0)
<         a, b = multiprocessing.Pipe()
<         p = multiprocessing.Process(target=self.signal_and_sleep,
---
>         sem = multiprocess.Semaphore(0)
>         a, b = multiprocess.Pipe()
>         p = multiprocess.Process(target=self.signal_and_sleep,
3846,3847c3849,3850
<         from multiprocessing.connection import wait
<         a, b = multiprocessing.Pipe()
---
>         from multiprocess.connection import wait
>         a, b = multiprocess.Pipe()
3865c3868
<             multiprocessing.connection.Listener(r'\\.\test')
---
>             multiprocess.connection.Listener(r'\\.\test')
3870c3873
<             multiprocessing.connection.Listener('/var/test.pipe')
---
>             multiprocess.connection.Listener('/var/test.pipe')
3884,3885c3887,3888
<         r, w = multiprocessing.Pipe(duplex=False)
<         p = multiprocessing.Process(target=cls.run_in_grandchild, args=(w,))
---
>         r, w = multiprocess.Pipe(duplex=False)
>         p = multiprocess.Process(target=cls.run_in_grandchild, args=(w,))
3894c3897
<     def test_flags(self):
---
>     def _test_flags(self):
3897c3900
<         prog = ('from test._test_multiprocessing import TestFlags; ' +
---
>         prog = ('from multiprocess.tests import TestFlags; ' +
3914c3917
<         conn = multiprocessing.connection.Client(address)
---
>         conn = multiprocess.connection.Client(address)
3922,3924c3925,3927
<             parent, child = multiprocessing.Pipe(duplex=True)
<             l = multiprocessing.connection.Listener(family='AF_INET')
<             p = multiprocessing.Process(target=self._test_timeout,
---
>             parent, child = multiprocess.Pipe(duplex=True)
>             l = multiprocess.connection.Listener(family='AF_INET')
>             p = multiprocess.Process(target=self._test_timeout,
3943,3944c3946,3947
<     def test_noforkbomb(self):
<         sm = multiprocessing.get_start_method()
---
>     def _test_noforkbomb(self):
>         sm = multiprocess.get_start_method()
3967c3970
<             p = multiprocessing.Process(target=cls.child, args=(n-1, conn))
---
>             p = multiprocess.Process(target=cls.child, args=(n-1, conn))
3976c3979
<         r, w = multiprocessing.Pipe(False)
---
>         r, w = multiprocess.Pipe(False)
3979c3982
<         p = multiprocessing.Process(target=self.child, args=(5, w))
---
>         p = multiprocess.Process(target=self.child, args=(5, w))
4030c4033
<         reader, writer = multiprocessing.Pipe()
---
>         reader, writer = multiprocess.Pipe()
4033c4036
<             p = multiprocessing.Process(target=self._test_closefds,
---
>             p = multiprocess.Process(target=self._test_closefds,
4044c4047
<         if multiprocessing.get_start_method() == 'fork':
---
>         if multiprocess.get_start_method() == 'fork':
4058c4061
<     # Sending CONN_MAX_SIZE bytes into a multiprocessing pipe must block
---
>     # Sending CONN_MAX_SIZE bytes into a multiprocess pipe must block
4073c4076
<         conn, child_conn = multiprocessing.Pipe()
---
>         conn, child_conn = multiprocess.Pipe()
4075c4078
<             p = multiprocessing.Process(target=self._test_ignore,
---
>             p = multiprocess.Process(target=self._test_ignore,
4099c4102
<         with multiprocessing.connection.Listener() as l:
---
>         with multiprocess.connection.Listener() as l:
4106c4109
<         conn, child_conn = multiprocessing.Pipe()
---
>         conn, child_conn = multiprocess.Pipe()
4108c4111
<             p = multiprocessing.Process(target=self._test_ignore_listener,
---
>             p = multiprocess.Process(target=self._test_ignore_listener,
4117c4120
<             client = multiprocessing.connection.Client(address)
---
>             client = multiprocess.connection.Client(address)
4126c4129
<         conn.send(multiprocessing.get_start_method())
---
>         conn.send(multiprocess.get_start_method())
4138c4141
<     def test_context(self):
---
>     def _test_context(self):
4141c4144
<                 ctx = multiprocessing.get_context(method)
---
>                 ctx = multiprocess.get_context(method)
4150,4151c4153,4154
<     def test_set_get(self):
<         multiprocessing.set_forkserver_preload(PRELOAD)
---
>     def _test_set_get(self):
>         multiprocess.set_forkserver_preload(PRELOAD)
4153c4156
<         old_method = multiprocessing.get_start_method()
---
>         old_method = multiprocess.get_start_method()
4157c4160
<                     multiprocessing.set_start_method(method, force=True)
---
>                     multiprocess.set_start_method(method, force=True)
4160,4161c4163,4164
<                 self.assertEqual(multiprocessing.get_start_method(), method)
<                 ctx = multiprocessing.get_context()
---
>                 self.assertEqual(multiprocess.get_start_method(), method)
>                 ctx = multiprocess.get_context()
4166c4169
<                 self.check_context(multiprocessing)
---
>                 self.check_context(multiprocess)
4169c4172
<             multiprocessing.set_start_method(old_method, force=True)
---
>             multiprocess.set_start_method(old_method, force=True)
4173c4176
<         methods = multiprocessing.get_all_start_methods()
---
>         methods = multiprocess.get_all_start_methods()
4181c4184
<         if multiprocessing.get_start_method() != 'forkserver':
---
>         if multiprocess.get_start_method() != 'forkserver':
4197c4200
<     def test_semaphore_tracker(self):
---
>     def _test_semaphore_tracker(self):
4203c4206
<             import multiprocessing as mp, time, os
---
>             import multiprocess as mp, time, os
4237c4240
<         from multiprocessing.semaphore_tracker import _semaphore_tracker
---
>         from multiprocess.semaphore_tracker import _semaphore_tracker
4243c4246
<         ctx = multiprocessing.get_context("spawn")
---
>         ctx = multiprocess.get_context("spawn")
4281,4283c4284,4286
<         queue = multiprocessing.SimpleQueue()
<         child_can_start = multiprocessing.Event()
<         parent_can_continue = multiprocessing.Event()
---
>         queue = multiprocess.SimpleQueue()
>         child_can_start = multiprocess.Event()
>         parent_can_continue = multiprocess.Event()
4285c4288
<         proc = multiprocessing.Process(
---
>         proc = multiprocess.Process(
4311c4314
<         cls.dangling = (multiprocessing.process._dangling.copy(),
---
>         cls.dangling = (multiprocess.process._dangling.copy(),
4316c4319
<         # bpo-26762: Some multiprocessing objects like Pool create reference
---
>         # bpo-26762: Some multiprocess objects like Pool create reference
4320c4323
<         processes = set(multiprocessing.process._dangling) - set(cls.dangling[0])
---
>         processes = set(multiprocess.process._dangling) - set(cls.dangling[0])
4335,4353c4338,4356
<     Process = multiprocessing.Process
<     connection = multiprocessing.connection
<     current_process = staticmethod(multiprocessing.current_process)
<     active_children = staticmethod(multiprocessing.active_children)
<     Pool = staticmethod(multiprocessing.Pool)
<     Pipe = staticmethod(multiprocessing.Pipe)
<     Queue = staticmethod(multiprocessing.Queue)
<     JoinableQueue = staticmethod(multiprocessing.JoinableQueue)
<     Lock = staticmethod(multiprocessing.Lock)
<     RLock = staticmethod(multiprocessing.RLock)
<     Semaphore = staticmethod(multiprocessing.Semaphore)
<     BoundedSemaphore = staticmethod(multiprocessing.BoundedSemaphore)
<     Condition = staticmethod(multiprocessing.Condition)
<     Event = staticmethod(multiprocessing.Event)
<     Barrier = staticmethod(multiprocessing.Barrier)
<     Value = staticmethod(multiprocessing.Value)
<     Array = staticmethod(multiprocessing.Array)
<     RawValue = staticmethod(multiprocessing.RawValue)
<     RawArray = staticmethod(multiprocessing.RawArray)
---
>     Process = multiprocess.Process
>     connection = multiprocess.connection
>     current_process = staticmethod(multiprocess.current_process)
>     active_children = staticmethod(multiprocess.active_children)
>     Pool = staticmethod(multiprocess.Pool)
>     Pipe = staticmethod(multiprocess.Pipe)
>     Queue = staticmethod(multiprocess.Queue)
>     JoinableQueue = staticmethod(multiprocess.JoinableQueue)
>     Lock = staticmethod(multiprocess.Lock)
>     RLock = staticmethod(multiprocess.RLock)
>     Semaphore = staticmethod(multiprocess.Semaphore)
>     BoundedSemaphore = staticmethod(multiprocess.BoundedSemaphore)
>     Condition = staticmethod(multiprocess.Condition)
>     Event = staticmethod(multiprocess.Event)
>     Barrier = staticmethod(multiprocess.Barrier)
>     Value = staticmethod(multiprocess.Value)
>     Array = staticmethod(multiprocess.Array)
>     RawValue = staticmethod(multiprocess.RawValue)
>     RawArray = staticmethod(multiprocess.RawArray)
4358c4361
<     Process = multiprocessing.Process
---
>     Process = multiprocess.Process
4381c4384
<         cls.manager = multiprocessing.Manager()
---
>         cls.manager = multiprocess.Manager()
4390c4393
<         while len(multiprocessing.active_children()) > 1:
---
>         while len(multiprocess.active_children()) > 1:
4395c4398
<                 print("Warning -- multiprocessing.Manager still has %s active "
---
>                 print("Warning -- multiprocess.Manager still has %s active "
4397c4400
<                       % (multiprocessing.active_children(), dt),
---
>                       % (multiprocess.active_children(), dt),
4418,4434c4421,4437
<     Process = multiprocessing.dummy.Process
<     connection = multiprocessing.dummy.connection
<     current_process = staticmethod(multiprocessing.dummy.current_process)
<     active_children = staticmethod(multiprocessing.dummy.active_children)
<     Pool = staticmethod(multiprocessing.dummy.Pool)
<     Pipe = staticmethod(multiprocessing.dummy.Pipe)
<     Queue = staticmethod(multiprocessing.dummy.Queue)
<     JoinableQueue = staticmethod(multiprocessing.dummy.JoinableQueue)
<     Lock = staticmethod(multiprocessing.dummy.Lock)
<     RLock = staticmethod(multiprocessing.dummy.RLock)
<     Semaphore = staticmethod(multiprocessing.dummy.Semaphore)
<     BoundedSemaphore = staticmethod(multiprocessing.dummy.BoundedSemaphore)
<     Condition = staticmethod(multiprocessing.dummy.Condition)
<     Event = staticmethod(multiprocessing.dummy.Event)
<     Barrier = staticmethod(multiprocessing.dummy.Barrier)
<     Value = staticmethod(multiprocessing.dummy.Value)
<     Array = staticmethod(multiprocessing.dummy.Array)
---
>     Process = multiprocess.dummy.Process
>     connection = multiprocess.dummy.connection
>     current_process = staticmethod(multiprocess.dummy.current_process)
>     active_children = staticmethod(multiprocess.dummy.active_children)
>     Pool = staticmethod(multiprocess.dummy.Pool)
>     Pipe = staticmethod(multiprocess.dummy.Pipe)
>     Queue = staticmethod(multiprocess.dummy.Queue)
>     JoinableQueue = staticmethod(multiprocess.dummy.JoinableQueue)
>     Lock = staticmethod(multiprocess.dummy.Lock)
>     RLock = staticmethod(multiprocess.dummy.RLock)
>     Semaphore = staticmethod(multiprocess.dummy.Semaphore)
>     BoundedSemaphore = staticmethod(multiprocess.dummy.BoundedSemaphore)
>     Condition = staticmethod(multiprocess.dummy.Condition)
>     Event = staticmethod(multiprocess.dummy.Event)
>     Barrier = staticmethod(multiprocess.dummy.Barrier)
>     Value = staticmethod(multiprocess.dummy.Value)
>     Array = staticmethod(multiprocess.dummy.Array)
4471,4473c4474,4476
<         multiprocessing.set_forkserver_preload(PRELOAD)
<         multiprocessing.process._cleanup()
<         dangling[0] = multiprocessing.process._dangling.copy()
---
>         multiprocess.set_forkserver_preload(PRELOAD)
>         multiprocess.process._cleanup()
>         dangling[0] = multiprocess.process._dangling.copy()
4475c4478
<         old_start_method[0] = multiprocessing.get_start_method(allow_none=True)
---
>         old_start_method[0] = multiprocess.get_start_method(allow_none=True)
4477c4480
<             multiprocessing.set_start_method(start_method, force=True)
---
>             multiprocess.set_start_method(start_method, force=True)
4484c4487
<                 lock = multiprocessing.RLock()
---
>                 lock = multiprocess.RLock()
4490c4493
<         multiprocessing.get_logger().setLevel(LOG_LEVEL)
---
>         multiprocess.get_logger().setLevel(LOG_LEVEL)
4495c4498
<         # bpo-26762: Some multiprocessing objects like Pool create reference
---
>         # bpo-26762: Some multiprocess objects like Pool create reference
4499c4502
<         multiprocessing.set_start_method(old_start_method[0], force=True)
---
>         multiprocess.set_start_method(old_start_method[0], force=True)
4501c4504
<         processes = set(multiprocessing.process._dangling) - set(dangling[0])
---
>         processes = set(multiprocess.process._dangling) - set(dangling[0])
4518c4521
<         multiprocessing.process._cleanup()
---
>         multiprocess.process._cleanup()
diff Python-3.6.13/Lib/test/mp_preload.py tests/mp_preload.py 
1c1
< import multiprocessing
---
> import multiprocessing as multiprocess
3c3
< multiprocessing.Lock()
---
> multiprocess.Lock()
11c11
<     ctx = multiprocessing.get_context("forkserver")
---
>     ctx = multiprocess.get_context("forkserver")
diff Python-3.6.13/Lib/test/mp_fork_bomb.py tests/mp_fork_bomb.py 
1c1
< import multiprocessing, sys
---
> import multiprocessing as multiprocess, sys
11c11
<     multiprocessing.set_start_method(sys.argv[1])
---
>     multiprocess.set_start_method(sys.argv[1])
13c13
<     multiprocessing.set_start_method('spawn')
---
>     multiprocess.set_start_method('spawn')
15c15
< p = multiprocessing.Process(target=foo)
---
> p = multiprocess.Process(target=foo)
