"""
Table Comparator for grammar and model information

Classes:
    - :class:`~seqgra.comparator.tablecomparator.TableComparator`: collects grammar and model information in text file
"""
from typing import List, Optional, Tuple
import os

import numpy as np
import pandas as pd
from scipy import interp
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import average_precision_score

import seqgra.constants as c
from seqgra.comparator import Comparator
from seqgra import Metrics
from seqgra.schema import DataSessionInfo, ModelSessionInfo


class TableComparator(Comparator):
    def __init__(self, analysis_id: str, output_dir: str,
                 model_labels: Optional[List[str]] = None,
                 silent: bool = False) -> None:
        super().__init__(c.ComparatorID.TABLE, "Table", analysis_id,
                         output_dir, model_labels, silent)

    def compare_models(self, grammar_ids: Optional[List[str]] = None,
                       model_ids: Optional[List[str]] = None,
                       set_names: List[str] = None) -> None:
        if not set_names:
            set_names = ["test"]

        grammar_id_column: List[str] = list()
        model_id_column: List[str] = list()
        set_name_column: List[str] = list()
        d_seqgra_version_column: List[str] = list()
        d_numpy_version_column: List[str] = list()
        d_python_version_column: List[str] = list()
        d_training_set_size_column: List[int] = list()
        d_validation_set_size_column: List[int] = list()
        d_test_set_size_column: List[int] = list()
        d_num_labels_column: List[int] = list()
        m_seqgra_version_column: List[str] = list()
        m_numpy_version_column: List[str] = list()
        m_python_version_column: List[str] = list()
        m_library_column: List[str] = list()
        m_library_version_column: List[str] = list()
        m_last_epoch_completed_column: List[int] = list()
        m_trainable_params_column: List[int] = list()
        m_non_trainable_params_column: List[int] = list()
        m_all_params_column: List[int] = list()
        e_metrics_loss_column: List[float] = list()
        e_metrics_accuracy_column: List[float] = list()
        e_roc_micro_auc_column: List[float] = list()
        e_roc_macro_auc_column: List[float] = list()
        e_pr_micro_auc_column: List[float] = list()
        e_pr_macro_auc_column: List[float] = list()

        for grammar_id in grammar_ids:
            data_session_info: DataSessionInfo = self.get_data_session_info(
                grammar_id)
            training_set_size: int = self.get_set_size(grammar_id, "training")
            validation_set_size: int = self.get_set_size(grammar_id,
                                                         "validation")
            test_set_size: int = self.get_set_size(grammar_id, "test")

            for model_id in model_ids:
                model_folder: str = self.model_dir + grammar_id + "/" + \
                    model_id
                if os.path.isdir(model_folder):
                    model_session_info: ModelSessionInfo = \
                        self.get_model_session_info(grammar_id, model_id)
                    last_epoch_completed: int = self.get_last_epoch_completed(
                        grammar_id, model_id)
                    trainable_params, non_trainable_params, all_params = \
                        self.get_model_params(grammar_id, model_id)
                    for set_name in set_names:
                        labels: List[str] = self.get_labels(grammar_id,
                                                            model_id, set_name)
                        if labels is None:
                            num_labels: int = np.nan
                        else:
                            num_labels: int = len(labels)

                        metrics_loss, metrics_accuracy = self.get_metrics(
                            grammar_id, model_id, set_name)
                        roc_micro_auc, roc_macro_auc = self.get_roc_auc(
                            grammar_id, model_id, set_name)
                        pr_micro_auc, pr_macro_auc = self.get_pr_auc(
                            grammar_id, model_id, set_name)

                        grammar_id_column.append(grammar_id)
                        model_id_column.append(model_id)
                        set_name_column.append(set_name)
                        d_seqgra_version_column.append(
                            data_session_info.seqgra_version)
                        d_numpy_version_column.append(
                            data_session_info.numpy_version)
                        d_python_version_column.append(
                            data_session_info.python_version)
                        d_training_set_size_column.append(training_set_size)
                        d_validation_set_size_column.append(
                            validation_set_size)
                        d_test_set_size_column.append(test_set_size)
                        d_num_labels_column.append(num_labels)
                        m_seqgra_version_column.append(
                            model_session_info.seqgra_version)
                        m_numpy_version_column.append(
                            model_session_info.numpy_version)
                        m_python_version_column.append(
                            model_session_info.python_version)
                        m_library_column.append(model_session_info.library)
                        m_library_version_column.append(
                            model_session_info.library_version)
                        m_last_epoch_completed_column.append(
                            last_epoch_completed)
                        m_trainable_params_column.append(trainable_params)
                        m_non_trainable_params_column.append(
                            non_trainable_params)
                        m_all_params_column.append(all_params)
                        e_metrics_loss_column.append(metrics_loss)
                        e_metrics_accuracy_column.append(metrics_accuracy)
                        e_roc_micro_auc_column.append(roc_micro_auc)
                        e_roc_macro_auc_column.append(roc_macro_auc)
                        e_pr_micro_auc_column.append(pr_micro_auc)
                        e_pr_macro_auc_column.append(pr_macro_auc)

        df = pd.DataFrame(
            {"grammar_id": grammar_id_column,
             "model_id": model_id_column,
             "set_name": set_name_column,
             "d_seqgra_version": d_seqgra_version_column,
             "d_numpy_version": d_numpy_version_column,
             "d_python_version": d_python_version_column,
             "d_training_set_size": d_training_set_size_column,
             "d_validation_set_size": d_validation_set_size_column,
             "d_test_set_size": d_test_set_size_column,
             "d_num_labels": d_num_labels_column,
             "m_seqgra_version": m_seqgra_version_column,
             "m_numpy_version": m_numpy_version_column,
             "m_python_version": m_python_version_column,
             "m_library": m_library_column,
             "m_library_version": m_library_version_column,
             "m_last_epoch_completed": m_last_epoch_completed_column,
             "m_trainable_params": m_trainable_params_column,
             "m_non_trainable_params": m_non_trainable_params_column,
             "m_all_params": m_all_params_column,
             "e_metrics_loss": e_metrics_loss_column,
             "e_metrics_accuracy": e_metrics_accuracy_column,
             "e_roc_micro_auc": e_roc_micro_auc_column,
             "e_roc_macro_auc": e_roc_macro_auc_column,
             "e_pr_micro_auc": e_pr_micro_auc_column,
             "e_pr_macro_auc": e_pr_macro_auc_column})
        df.to_csv(self.output_dir + "table.txt", sep="\t", index=False)

    def get_set_size(self, grammar_id: str, set_name: str) -> int:
        set_file_name: str = self.data_dir + grammar_id + "/" + \
            set_name + ".txt"
        if os.path.isfile(set_file_name):
            # do not count header
            i: int = -1
            with open(set_file_name) as f:
                for line in f:
                    i += 1
            return i
        else:
            self.logger.warning("file does not exist: %s",
                                set_file_name)
            return np.nan

    @staticmethod
    def _read_lines(file_name: str) -> Optional[List[str]]:
        if os.path.isfile(file_name):
            with open(file_name) as f:
                return f.readlines()
        else:
            return None

    @staticmethod
    def _get_property(lines: List[str], name: str) -> str:
        for line in lines:
            if line.startswith(name):
                return line.replace(name, "").strip()

        return ""

    def get_data_session_info(self, grammar_id: str) -> DataSessionInfo:
        file_name: str = self.data_dir + grammar_id + "/session-info.txt"
        lines: List[str] = TableComparator._read_lines(file_name)
        if lines:
            seqgra_version: str = TableComparator._get_property(
                lines, "seqgra package version: ")
            numpy_version: str = TableComparator._get_property(
                lines, "NumPy version: ")
            python_version: str = TableComparator._get_property(
                lines, "Python version: ")
            return DataSessionInfo(seqgra_version, numpy_version,
                                   python_version)
        else:
            self.logger.warning("file does not exist: %s",
                                file_name)
            return DataSessionInfo("", "", "")

    def get_model_session_info(self, grammar_id: str,
                               model_id: str) -> ModelSessionInfo:
        file_name: str = self.model_dir + grammar_id + "/" + \
            model_id + "/session-info.txt"
        lines: List[str] = TableComparator._read_lines(file_name)

        if lines:
            seqgra_version: str = TableComparator._get_property(
                lines, "seqgra package version: ")
            numpy_version: str = TableComparator._get_property(
                lines, "NumPy version: ")
            python_version: str = TableComparator._get_property(
                lines, "Python version: ")
            pytorch_version: str = TableComparator._get_property(
                lines, "PyTorch version: ")
            tf_version: str = TableComparator._get_property(
                lines, "TensorFlow version: ")

            if pytorch_version:
                return ModelSessionInfo(seqgra_version,
                                        numpy_version,
                                        python_version,
                                        "PyTorch",
                                        pytorch_version)
            elif tf_version:
                return ModelSessionInfo(seqgra_version,
                                        numpy_version,
                                        python_version,
                                        "TensorFlow",
                                        tf_version)
            else:
                return ModelSessionInfo(seqgra_version,
                                        numpy_version,
                                        python_version,
                                        "Bayes Optimal Classifier",
                                        seqgra_version)
        else:
            self.logger.warning("file does not exist: %s",
                                file_name)
            return ModelSessionInfo("", "", "", "", "")

    def get_last_epoch_completed(self, grammar_id: str, model_id: str) -> int:
        file_name: str = self.model_dir + grammar_id + "/" + \
            model_id + "/last-epoch-completed.txt"
        last_epoch: int = np.nan
        if os.path.isfile(file_name):
            with open(file_name) as f:
                last_epoch = int(f.readline().strip())
        else:
            self.logger.warning("file does not exist: %s",
                                file_name)

        return last_epoch

    def get_model_params(self, grammar_id: str,
                         model_id: str) -> Tuple[int, int, int]:
        model_params_file_name: str = self.model_dir + grammar_id + "/" + \
            model_id + "/num-model-parameters.txt"
        trainable_params: int = np.nan
        non_trainable_params: int = np.nan
        all_params: int = np.nan
        if os.path.isfile(model_params_file_name):
            with open(model_params_file_name) as f:
                trainable_params = int(f.readline().strip().split("\t")[1])
                non_trainable_params = int(f.readline().strip().split("\t")[1])
                all_params = int(f.readline().strip().split("\t")[1])
        else:
            self.logger.warning("file does not exist: %s",
                                model_params_file_name)

        return trainable_params, non_trainable_params, all_params

    def get_metrics(self, grammar_id: str, model_id: str,
                    set_name: str) -> Metrics:
        metrics_file_name: str = self.evaluation_dir + \
            grammar_id + "/" + \
            model_id + "/" + c.EvaluatorID.METRICS + \
            "/" + set_name + "-metrics.txt"
        if os.path.isfile(metrics_file_name):
            df = pd.read_csv(metrics_file_name, sep="\t")

            loss = df[df["metric"] == "loss"]
            accuracy = df[df["metric"] == "accuracy"]

            return Metrics(loss.iloc[0]["value"], accuracy.iloc[0]["value"])
        else:
            self.logger.warning("file does not exist: %s",
                                metrics_file_name)
            return Metrics(np.nan, np.nan)

    def get_roc_auc(self, grammar_id: str, model_id: str,
                    set_name: str) -> [float, float]:
        predict_file_name: str = self.evaluation_dir + \
            grammar_id + "/" + \
            model_id + "/" + c.EvaluatorID.PREDICT + \
            "/" + set_name + "-y-hat.txt"
        if os.path.isfile(predict_file_name):
            df = pd.read_csv(predict_file_name, sep="\t")
            num_labels: int = int(len(df.columns) / 2)
            y_df = df.iloc[:, 0:num_labels]
            y_hat_df = df.iloc[:, num_labels:len(df.columns)]

            micro_fpr, micro_tpr, _ = roc_curve(y_df.values.ravel(),
                                                y_hat_df.values.ravel())
            roc_micro_auc = auc(micro_fpr, micro_tpr)

            fpr = dict()
            tpr = dict()
            for i in range(num_labels):
                fpr[i], tpr[i], _ = roc_curve(y_df.values[:, i],
                                              y_hat_df.values[:, i])

            all_fpr = np.unique(np.concatenate([fpr[i]
                                                for i in range(num_labels)]))
            mean_tpr = np.zeros_like(all_fpr)
            for i in range(num_labels):
                mean_tpr += interp(all_fpr, fpr[i], tpr[i])

            mean_tpr /= num_labels

            roc_macro_auc = auc(all_fpr, mean_tpr)

            return (roc_micro_auc, roc_macro_auc)
        else:
            self.logger.warning("file does not exist: %s",
                                predict_file_name)
            return (np.nan, np.nan)

    def get_pr_auc(self, grammar_id: str, model_id: str,
                   set_name: str) -> [float, float]:
        predict_file_name: str = self.evaluation_dir + \
            grammar_id + "/" + \
            model_id + "/" + c.EvaluatorID.PREDICT + \
            "/" + set_name + "-y-hat.txt"
        if os.path.isfile(predict_file_name):
            df = pd.read_csv(predict_file_name, sep="\t")
            num_labels: int = int(len(df.columns) / 2)
            y_df = df.iloc[:, 0:num_labels]
            y_hat_df = df.iloc[:, num_labels:len(df.columns)]

            pr_micro_auc = average_precision_score(y_df.values,
                                                   y_hat_df.values,
                                                   average="micro")
            pr_macro_auc = average_precision_score(y_df.values,
                                                   y_hat_df.values,
                                                   average="macro")

            return (pr_micro_auc, pr_macro_auc)
        else:
            self.logger.warning("file does not exist: %s",
                                predict_file_name)
            return (np.nan, np.nan)
